{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Project 3: Airbnb\n",
    "**This is the third of three mandatory projects to be handed in as part of the assessment for the course 02807 Computational Tools for Data Science at Technical University of Denmark, autumn 2019.**\n",
    "\n",
    "#### Practical info\n",
    "- **The project is to be done in groups of at most 3 students**\n",
    "- **Each group has to hand in _one_ Jupyter notebook (this notebook) with their solution**\n",
    "- **The hand-in of the notebook is due 2019-12-05, 23:59 on DTU Inside**\n",
    "\n",
    "#### Your solution\n",
    "- **Your solution should be in Python/PySpark**\n",
    "- **For each question you may use as many cells for your solution as you like**\n",
    "- **You should not remove the problem statements**\n",
    "- **Your notebook should be runnable, i.e., clicking [>>] in Jupyter should generate the result that you want to be assessed**\n",
    "- **You are not expected to use machine learning to solve any of the exercises**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Introduction\n",
    "[Airbnb](http://airbnb.com) is an online marketplace for arranging or offering lodgings. In this project you will use Spark to analyze data obtained from the Airbnb website. The purpose of the analysis is to extract information about trends and patterns from the data.\n",
    "\n",
    "The project has two parts.\n",
    "\n",
    "### Part 1: Loading, describing and preparing the data\n",
    "There's quite a lot of data. Make sure that you can load and correctly parse the data, and that you understand what the dataset contains. You should also prepare the data for the analysis in part two. This means cleaning it and staging it so that subsequent queries are fast.\n",
    "\n",
    "### Par 2: Analysis\n",
    "In this part your goal is to learn about trends and usage patterns from the data. You should give solutions to the tasks defined in this notebook, and you should use Spark to do the data processing. You may use other libraries like for instance Pandas and matplotlib for visualisation.\n",
    "\n",
    "## Guidelines\n",
    "- Processing data should be done using Spark. Once data has been reduced to aggregate form, you may use collect to extract it into Python for visualisation.\n",
    "- Your solutions will be evaluated by correctness, code quality and interpretability of the output. This means that you have to write clean and efficient Spark code that will generate sensible execution plans, and that the tables and visualisations that you produce are meaningful and easy to read.\n",
    "- You may add more cells for your solutions, but you should not modify the notebook otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Reference websites\n",
    "http://nadbordrozd.github.io/blog/2016/05/22/one-weird-trick-that-will-fix-your-pyspark-schemas/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Create Spark session and define imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext #https://www.tutorialspoint.com/pyspark/pyspark_sparkcontext.htm\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "try:\n",
    "    SparkContext.stop(sc)\n",
    "except:\n",
    "    pass\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '4g')\n",
    "SparkContext.setSystemProperty('spark.executor.instances', '4')\n",
    "\n",
    "sc = SparkContext(\"local\", \"SparkProject3\") #spark context https://www.tutorialspoint.com/pyspark/pyspark_sparkcontext.htm\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SparkProject3\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"SparkProject3\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.types as pst\n",
    "from pyspark.sql import Row\n",
    "\n",
    "def infer_schema(rec):\n",
    "    \"\"\"infers dataframe schema for a record. Assumes every dict is a Struct, not a Map\"\"\"\n",
    "    if isinstance(rec, dict):\n",
    "        return pst.StructType([pst.StructField(key, infer_schema(value), True)\n",
    "                              for key, value in sorted(rec.items())])\n",
    "    elif isinstance(rec, list):\n",
    "        if len(rec) == 0:\n",
    "            raise ValueError(\"can't infer type of an empty list\")\n",
    "        elem_type = infer_schema(rec[0])\n",
    "        for elem in rec:\n",
    "            this_type = infer_schema(elem)\n",
    "            if elem_type != this_type:\n",
    "                raise ValueError(\"can't infer type of a list with inconsistent elem types\")\n",
    "        return pst.ArrayType(elem_type)\n",
    "    else:\n",
    "        return pst._infer_type(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def _rowify(x, prototype):\n",
    "    \"\"\"creates a Row object conforming to a schema as specified by a dict\"\"\"\n",
    "\n",
    "    def _equivalent_types(x, y):\n",
    "        if type(x) in [str, unicode] and type(y) in [str, unicode]:\n",
    "            return True\n",
    "        return isinstance(x, type(y)) or isinstance(y, type(x))\n",
    "\n",
    "    if x is None:\n",
    "        return None\n",
    "    elif isinstance(prototype, dict):\n",
    "        if type(x) != dict:\n",
    "            raise ValueError(\"expected dict, got %s instead\" % type(x))\n",
    "        rowified_dict = {}\n",
    "        for key, val in x.items():\n",
    "            if key not in prototype:\n",
    "                raise ValueError(\"got unexpected field %s\" % key)\n",
    "            rowified_dict[key] = _rowify(val, prototype[key])\n",
    "            for key in prototype:\n",
    "                if key not in x:\n",
    "                    raise ValueError(\n",
    "                        \"expected %s field but didn't find it\" % key)\n",
    "        return Row(**rowified_dict)\n",
    "    elif isinstance(prototype, list):\n",
    "        if type(x) != list:\n",
    "            raise ValueError(\"expected list, got %s instead\" % type(x))\n",
    "        return [_rowify(e, prototype[0]) for e in x]\n",
    "    else:\n",
    "        if not _equivalent_types(x, prototype):\n",
    "            raise ValueError(\"expected %s, got %s instead\" %\n",
    "                             (type(prototype), type(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def df_from_rdd(rdd, prototype, sql):\n",
    "    \"\"\"creates a dataframe out of an rdd of dicts, with schema inferred from a prototype record\"\"\"\n",
    "    schema = infer_schema(prototype)\n",
    "    row_rdd = rdd.map(lambda x: _rowify(x, prototype))\n",
    "    return sql.createDataFrame(row_rdd, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "df = df_from_rdd(rdd, prototype, sqlContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def read(path,f):\n",
    "    return spark.read.option('inferSchema', True).option('multiline', True).csv(path+f, escape='\"', header=True)\n",
    "\n",
    "def read_parquet(path,f):\n",
    "    return spark.read.parquet(path+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def disp(x, n):\n",
    "    \"\"\" Prettier spark dataframe printing with pandas\n",
    "        Args:\n",
    "            x: dataframe\n",
    "            n: number of rows to display\n",
    "    \"\"\"\n",
    "    return x.limit(n).toPandas().head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Part 1: Loading, describing and preparing the data\n",
    "The data comes in two files. Start by downloading the files and putting them in your `data/` folder.\n",
    "\n",
    "- [Listings](https://files.dtu.dk/u/siPzAasj8w2gI_ME/listings.csv?l) (5 GB)\n",
    "- [Reviews](https://files.dtu.dk/u/k3oaPYp6GjKBeho4/reviews.csv?l) (9.5 GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Load the data\n",
    "The data has multiline rows (rows that span multiple lines in the file). To correctly parse these you should use the `multiline` option and set the `escape` character to be `\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1232cb984c9e\n",
      " 1d8d2e302cd5\n",
      " 4c8a18b509eb\n",
      " 6193ebff96e2\n",
      " 6cd8b62f0451\n",
      " 8e04e5fe98a6\n",
      " 989f3b2baa52\n",
      " a53524a96747\n",
      " a674c35b66a1\n",
      " a7aedc881f2b\n",
      " arita_Project3_v2_0.ipynb\n",
      " data\n",
      " f495661be4ae\n",
      "'Mandatory Assignment 1 - Counting Words.ipynb'\n",
      "'Mandatory Assignment 2 - Sampling Customers.ipynb'\n",
      "'MySQL connection example.ipynb'\n",
      "'Project 1 - Customer Database.ipynb'\n",
      "'Project 2 - Web Traffic Analysis.ipynb'\n",
      "'Project 3 - Airbnb.ipynb'\n",
      "'SQLite connection example.ipynb'\n",
      " traffic_2_sample.tsv\n",
      " Using\n",
      "'Week 10 - Introduction to Spark.ipynb'\n",
      " week10.md\n",
      "'Week 10 - Spark UI Demo.ipynb'\n",
      "'Week 11 - Advanced Spark functions.ipynb'\n",
      "'Week 2 - Heart Disease Data Analysis.ipynb'\n",
      "'Week 2 - Python Highlights.ipynb'\n",
      "'Week 3 - Chuck Norris.ipynb'\n",
      "'Week 3 - Training a model using scikit-learn.ipynb'\n",
      "'Week 4 - Join exercises.ipynb'\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "root = 'data/'\n",
    "f1 = 'listings.parquet'\n",
    "path1 ='data/listings.csv'\n",
    "f2 ='reviews.parquet'\n",
    "path2 ='data/reviews.csv'\n",
    "delimiters = \",\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### First attempt...takes long to load the entire file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "path1 ='data/listings.csv'\n",
    "#path1 = 'https://files.dtu.dk/u/siPzAasj8w2gI_ME/listings.csv?l'\n",
    "df_listing = spark.read.option('inferSchema', True) \\\n",
    "                .option(\"delimiter\", delimiters)\\\n",
    "                .option('multiLine', True).csv(path1, escape = '\"',header= True)#.limit(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "path2 ='data/reviews.csv'\n",
    "df_reviews = spark.read.option('inferSchema', True) \\\n",
    "                .option(\"delimiter\", delimiters)\\\n",
    "                .option('multiLine', True).csv(path2, escape = '\"',header= True)#.limit(50)\n",
    "\n",
    "#spark.read.option('header', True).option('header', True).option(\"escape\", '\"').option('multiLine', True).csv(path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### using parquet? - Zachs code returns me error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "listings = read_parquet(path1,f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "reviews = read_parquet(path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "A possible alternative would be chunking in smaller portions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "def arichuck ():\n",
    "    chunksize 10**6\n",
    "    for chunk in spark.read(filename, chunksize):\n",
    "        process (chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "or try to load only a limited amount of lines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Describe the data\n",
    "List the features (schema) and sizes of the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "df_listing.show() #<--------------- veeeery shitty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>experiences_offered</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>...</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>is_business_travel_ready</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145320</td>\n",
       "      <td>https://www.airbnb.com/rooms/145320</td>\n",
       "      <td>20190928160308</td>\n",
       "      <td>2019-09-28</td>\n",
       "      <td>In the middle of it all - with a view!</td>\n",
       "      <td>Mitt boende passar par, kompisar och ensamäven...</td>\n",
       "      <td>A cozy three room flat with great personality....</td>\n",
       "      <td>Mitt boende passar par, kompisar och ensamäven...</td>\n",
       "      <td>none</td>\n",
       "      <td>The flat is in the area of Södermalm, the youn...</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155220</td>\n",
       "      <td>https://www.airbnb.com/rooms/155220</td>\n",
       "      <td>20190928160308</td>\n",
       "      <td>2019-09-28</td>\n",
       "      <td>Stockholm, new spacoius villa</td>\n",
       "      <td>Convenient and spacy home full of positive ene...</td>\n",
       "      <td>ABOUT THE HOUSE: Modern villa built in 2010. L...</td>\n",
       "      <td>ABOUT THE HOUSE: Modern villa built in 2010. L...</td>\n",
       "      <td>none</td>\n",
       "      <td>Close to nature and easy access to citylife.</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155685</td>\n",
       "      <td>https://www.airbnb.com/rooms/155685</td>\n",
       "      <td>20190928160308</td>\n",
       "      <td>2019-09-28</td>\n",
       "      <td>Hornstull with water view!</td>\n",
       "      <td>This apartment is located in the center of fun...</td>\n",
       "      <td>46 sqm apartment in Hornstulls, Södermalm Stoc...</td>\n",
       "      <td>This apartment is located in the center of fun...</td>\n",
       "      <td>none</td>\n",
       "      <td>There is a funky vibe here!</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164448</td>\n",
       "      <td>https://www.airbnb.com/rooms/164448</td>\n",
       "      <td>20190928160308</td>\n",
       "      <td>2019-09-28</td>\n",
       "      <td>Double room in central Stockholm with Wi-Fi</td>\n",
       "      <td>I am renting out a nice double room on the top...</td>\n",
       "      <td>ROOM: The room has a twin/double bed (2x90x200...</td>\n",
       "      <td>I am renting out a nice double room on the top...</td>\n",
       "      <td>none</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>flexible</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170651</td>\n",
       "      <td>https://www.airbnb.com/rooms/170651</td>\n",
       "      <td>20190928160308</td>\n",
       "      <td>2019-09-28</td>\n",
       "      <td>Petit Charm Rooftop next to heaven</td>\n",
       "      <td>None</td>\n",
       "      <td>Welcome to this beautiful, small, and charming...</td>\n",
       "      <td>Welcome to this beautiful, small, and charming...</td>\n",
       "      <td>none</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                          listing_url       scrape_id last_scraped  \\\n",
       "0  145320  https://www.airbnb.com/rooms/145320  20190928160308   2019-09-28   \n",
       "1  155220  https://www.airbnb.com/rooms/155220  20190928160308   2019-09-28   \n",
       "2  155685  https://www.airbnb.com/rooms/155685  20190928160308   2019-09-28   \n",
       "3  164448  https://www.airbnb.com/rooms/164448  20190928160308   2019-09-28   \n",
       "4  170651  https://www.airbnb.com/rooms/170651  20190928160308   2019-09-28   \n",
       "\n",
       "                                          name  \\\n",
       "0       In the middle of it all - with a view!   \n",
       "1                Stockholm, new spacoius villa   \n",
       "2                   Hornstull with water view!   \n",
       "3  Double room in central Stockholm with Wi-Fi   \n",
       "4           Petit Charm Rooftop next to heaven   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Mitt boende passar par, kompisar och ensamäven...   \n",
       "1  Convenient and spacy home full of positive ene...   \n",
       "2  This apartment is located in the center of fun...   \n",
       "3  I am renting out a nice double room on the top...   \n",
       "4                                               None   \n",
       "\n",
       "                                               space  \\\n",
       "0  A cozy three room flat with great personality....   \n",
       "1  ABOUT THE HOUSE: Modern villa built in 2010. L...   \n",
       "2  46 sqm apartment in Hornstulls, Södermalm Stoc...   \n",
       "3  ROOM: The room has a twin/double bed (2x90x200...   \n",
       "4  Welcome to this beautiful, small, and charming...   \n",
       "\n",
       "                                         description experiences_offered  \\\n",
       "0  Mitt boende passar par, kompisar och ensamäven...                none   \n",
       "1  ABOUT THE HOUSE: Modern villa built in 2010. L...                none   \n",
       "2  This apartment is located in the center of fun...                none   \n",
       "3  I am renting out a nice double room on the top...                none   \n",
       "4  Welcome to this beautiful, small, and charming...                none   \n",
       "\n",
       "                               neighborhood_overview  ... instant_bookable  \\\n",
       "0  The flat is in the area of Södermalm, the youn...  ...                t   \n",
       "1       Close to nature and easy access to citylife.  ...                f   \n",
       "2                        There is a funky vibe here!  ...                f   \n",
       "3                                               None  ...                t   \n",
       "4                                               None  ...                f   \n",
       "\n",
       "  is_business_travel_ready          cancellation_policy  \\\n",
       "0                        f  strict_14_with_grace_period   \n",
       "1                        f                     moderate   \n",
       "2                        f                     moderate   \n",
       "3                        f                     flexible   \n",
       "4                        f  strict_14_with_grace_period   \n",
       "\n",
       "  require_guest_profile_picture require_guest_phone_verification  \\\n",
       "0                             f                                f   \n",
       "1                             f                                f   \n",
       "2                             f                                f   \n",
       "3                             t                                t   \n",
       "4                             f                                f   \n",
       "\n",
       "  calculated_host_listings_count calculated_host_listings_count_entire_homes  \\\n",
       "0                              1                                           0   \n",
       "1                              2                                           2   \n",
       "2                              1                                           1   \n",
       "3                              2                                           0   \n",
       "4                              1                                           1   \n",
       "\n",
       "  calculated_host_listings_count_private_rooms  \\\n",
       "0                                            1   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            2   \n",
       "4                                            0   \n",
       "\n",
       "  calculated_host_listings_count_shared_rooms reviews_per_month  \n",
       "0                                           0              2.54  \n",
       "1                                           0              None  \n",
       "2                                           0              0.22  \n",
       "3                                           0              3.13  \n",
       "4                                           0              0.33  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_listing.limit(10).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- listing_url: string (nullable = true)\n",
      " |-- scrape_id: string (nullable = true)\n",
      " |-- last_scraped: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- space: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- experiences_offered: string (nullable = true)\n",
      " |-- neighborhood_overview: string (nullable = true)\n",
      " |-- notes: string (nullable = true)\n",
      " |-- transit: string (nullable = true)\n",
      " |-- access: string (nullable = true)\n",
      " |-- interaction: string (nullable = true)\n",
      " |-- house_rules: string (nullable = true)\n",
      " |-- thumbnail_url: string (nullable = true)\n",
      " |-- medium_url: string (nullable = true)\n",
      " |-- picture_url: string (nullable = true)\n",
      " |-- xl_picture_url: string (nullable = true)\n",
      " |-- host_id: string (nullable = true)\n",
      " |-- host_url: string (nullable = true)\n",
      " |-- host_name: string (nullable = true)\n",
      " |-- host_since: string (nullable = true)\n",
      " |-- host_location: string (nullable = true)\n",
      " |-- host_about: string (nullable = true)\n",
      " |-- host_response_time: string (nullable = true)\n",
      " |-- host_response_rate: string (nullable = true)\n",
      " |-- host_acceptance_rate: string (nullable = true)\n",
      " |-- host_is_superhost: string (nullable = true)\n",
      " |-- host_thumbnail_url: string (nullable = true)\n",
      " |-- host_picture_url: string (nullable = true)\n",
      " |-- host_neighbourhood: string (nullable = true)\n",
      " |-- host_listings_count: string (nullable = true)\n",
      " |-- host_total_listings_count: string (nullable = true)\n",
      " |-- host_verifications: string (nullable = true)\n",
      " |-- host_has_profile_pic: string (nullable = true)\n",
      " |-- host_identity_verified: string (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- neighbourhood_cleansed: string (nullable = true)\n",
      " |-- neighbourhood_group_cleansed: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- market: string (nullable = true)\n",
      " |-- smart_location: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- is_location_exact: string (nullable = true)\n",
      " |-- property_type: string (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- accommodates: string (nullable = true)\n",
      " |-- bathrooms: string (nullable = true)\n",
      " |-- bedrooms: string (nullable = true)\n",
      " |-- beds: string (nullable = true)\n",
      " |-- bed_type: string (nullable = true)\n",
      " |-- amenities: string (nullable = true)\n",
      " |-- square_feet: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- weekly_price: string (nullable = true)\n",
      " |-- monthly_price: string (nullable = true)\n",
      " |-- security_deposit: string (nullable = true)\n",
      " |-- cleaning_fee: string (nullable = true)\n",
      " |-- guests_included: string (nullable = true)\n",
      " |-- extra_people: string (nullable = true)\n",
      " |-- minimum_nights: string (nullable = true)\n",
      " |-- maximum_nights: string (nullable = true)\n",
      " |-- minimum_minimum_nights: string (nullable = true)\n",
      " |-- maximum_minimum_nights: string (nullable = true)\n",
      " |-- minimum_maximum_nights: string (nullable = true)\n",
      " |-- maximum_maximum_nights: string (nullable = true)\n",
      " |-- minimum_nights_avg_ntm: string (nullable = true)\n",
      " |-- maximum_nights_avg_ntm: string (nullable = true)\n",
      " |-- calendar_updated: string (nullable = true)\n",
      " |-- has_availability: string (nullable = true)\n",
      " |-- availability_30: string (nullable = true)\n",
      " |-- availability_60: string (nullable = true)\n",
      " |-- availability_90: string (nullable = true)\n",
      " |-- availability_365: string (nullable = true)\n",
      " |-- calendar_last_scraped: string (nullable = true)\n",
      " |-- number_of_reviews: string (nullable = true)\n",
      " |-- number_of_reviews_ltm: string (nullable = true)\n",
      " |-- first_review: string (nullable = true)\n",
      " |-- last_review: string (nullable = true)\n",
      " |-- review_scores_rating: string (nullable = true)\n",
      " |-- review_scores_accuracy: string (nullable = true)\n",
      " |-- review_scores_cleanliness: string (nullable = true)\n",
      " |-- review_scores_checkin: string (nullable = true)\n",
      " |-- review_scores_communication: string (nullable = true)\n",
      " |-- review_scores_location: string (nullable = true)\n",
      " |-- review_scores_value: string (nullable = true)\n",
      " |-- requires_license: string (nullable = true)\n",
      " |-- license: string (nullable = true)\n",
      " |-- jurisdiction_names: string (nullable = true)\n",
      " |-- instant_bookable: string (nullable = true)\n",
      " |-- is_business_travel_ready: string (nullable = true)\n",
      " |-- cancellation_policy: string (nullable = true)\n",
      " |-- require_guest_profile_picture: string (nullable = true)\n",
      " |-- require_guest_phone_verification: string (nullable = true)\n",
      " |-- calculated_host_listings_count: string (nullable = true)\n",
      " |-- calculated_host_listings_count_entire_homes: string (nullable = true)\n",
      " |-- calculated_host_listings_count_private_rooms: string (nullable = true)\n",
      " |-- calculated_host_listings_count_shared_rooms: string (nullable = true)\n",
      " |-- reviews_per_month: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_listing.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1330480"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_listing.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+-----------+-------------+--------------------+\n",
      "|listing_id|       id|      date|reviewer_id|reviewer_name|            comments|\n",
      "+----------+---------+----------+-----------+-------------+--------------------+\n",
      "|    145320|156423122|2017-05-30|  123386382|        Erwin|Prima plek om Sto...|\n",
      "|    145320|170211906|2017-07-15|  123091743|         Anne|Cosy and clean fl...|\n",
      "|    145320|172169175|2017-07-20|      78004|     Patricia|The host canceled...|\n",
      "|    145320|176647581|2017-07-31|  103178743|    Charlotte|Kim's place was o...|\n",
      "|    145320|185676021|2017-08-22|    4023961|    Alexander|great spacious ap...|\n",
      "|    145320|189668224|2017-09-02|  142869362|        Heiko|Kim is a very fri...|\n",
      "|    145320|191894030|2017-09-09|   25194419|        Jason|The apartment is ...|\n",
      "|    145320|193316070|2017-09-13|   52056015|        David|Nicely appointed,...|\n",
      "|    145320|196760607|2017-09-24|    3980456|        Janne|It was a pleasure...|\n",
      "|    145320|201885633|2017-10-09|   72139946|     Florence|Kim's place is si...|\n",
      "|    145320|203410181|2017-10-15|   23002655|      Charlie|We absolutely lov...|\n",
      "|    145320|210619953|2017-11-10|    3451329|      Natalia|Amazing place to ...|\n",
      "|    145320|211523951|2017-11-13|  105945750|       Ainhoa|Very pleasant sta...|\n",
      "|    145320|212932349|2017-11-19|     203826|           Fe|We had a wonderfu...|\n",
      "|    145320|214018139|2017-11-24|   70756436|       Marcel|Great location! C...|\n",
      "|    145320|216533345|2017-12-04|   10655526|      Shannon|Lovely flat in a ...|\n",
      "|    145320|219021131|2017-12-16|   29246547|          Dan|Kim’s flat is in ...|\n",
      "|    145320|231273225|2018-01-31|  160717975|          Sam|I would definitel...|\n",
      "|    145320|233159940|2018-02-08|   33212603|       Katina|Kim's place is pe...|\n",
      "|    145320|234271335|2018-02-12|  160422715|      Kensuke|The flat is so co...|\n",
      "+----------+---------+----------+-----------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviews.limit(20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- listing_id: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- reviewer_id: string (nullable = true)\n",
      " |-- reviewer_name: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviews.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "df_reviews.count() # heavy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "df = df_listing.join(df_reviews, ['ColumnNameInCommon'], 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "ldf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Prepare the data for analysis\n",
    "You should prepare two dataframes to be used in the analysis part of the project. You should not be concerned with cleaning the data. There's a lot of it, so it will be sufficient to drop rows that have bad values. You may want to go back and refine this step at a later point when doing the analysis.\n",
    "\n",
    "You may also want to consider if you can stage your data so that subsequent processing is more efficient (this is not strictly necessary for Spark to run, but you may be able to decrease the time you sit around waiting for Spark to finish things)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 1- keeping necessary columns from listing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We decide to keep less columns: \n",
    "\n",
    " |-- id: string (nullable = true)\n",
    " \n",
    " |-- summary: string (nullable = true)\n",
    " \n",
    " |-- description: string (nullable = true)\n",
    " \n",
    " |-- property_type: string (nullable = true)\n",
    " \n",
    " |-- neighbourhood: string (nullable = true)\n",
    " \n",
    " |-- neighbourhood_group_cleansed: string (nullable = true)\n",
    " \n",
    " |-- city: string (nullable = true)\n",
    " \n",
    " |-- zipcode: string (nullable = true)\n",
    " \n",
    " |-- country_code: string (nullable = true)\n",
    " \n",
    " |-- country: string (nullable = true)\n",
    " \n",
    " |-- price: string (nullable = true)\n",
    " \n",
    " |-- review_scores_rating: string (nullable = true)\n",
    " \n",
    " |-- reviews_per_month: string (nullable = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_listing_clean = df_listing.select([c for c in df_listing.columns if c in ['id','summary','description','property_type','neighbourhood','neighbourhood_group_cleansed','city','zipcode','country_code','country','price','review_scores_rating','reviews_per_month']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>neighbourhood_group_cleansed</th>\n",
       "      <th>city</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country</th>\n",
       "      <th>property_type</th>\n",
       "      <th>price</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145320</td>\n",
       "      <td>Mitt boende passar par, kompisar och ensamäven...</td>\n",
       "      <td>Mitt boende passar par, kompisar och ensamäven...</td>\n",
       "      <td>Södermalm</td>\n",
       "      <td>None</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>118 53</td>\n",
       "      <td>SE</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$1,272.00</td>\n",
       "      <td>97</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155220</td>\n",
       "      <td>Convenient and spacy home full of positive ene...</td>\n",
       "      <td>ABOUT THE HOUSE: Modern villa built in 2010. L...</td>\n",
       "      <td>Skarpnäck</td>\n",
       "      <td>None</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>None</td>\n",
       "      <td>SE</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>House</td>\n",
       "      <td>$1,203.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155685</td>\n",
       "      <td>This apartment is located in the center of fun...</td>\n",
       "      <td>This apartment is located in the center of fun...</td>\n",
       "      <td>Södermalm</td>\n",
       "      <td>None</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>11739</td>\n",
       "      <td>SE</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$3,209.00</td>\n",
       "      <td>94</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164448</td>\n",
       "      <td>I am renting out a nice double room on the top...</td>\n",
       "      <td>I am renting out a nice double room on the top...</td>\n",
       "      <td>Södermalm</td>\n",
       "      <td>None</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>11864</td>\n",
       "      <td>SE</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$597.00</td>\n",
       "      <td>97</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170651</td>\n",
       "      <td>None</td>\n",
       "      <td>Welcome to this beautiful, small, and charming...</td>\n",
       "      <td>Södermalm</td>\n",
       "      <td>None</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>11737</td>\n",
       "      <td>SE</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$734.00</td>\n",
       "      <td>93</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                            summary  \\\n",
       "0  145320  Mitt boende passar par, kompisar och ensamäven...   \n",
       "1  155220  Convenient and spacy home full of positive ene...   \n",
       "2  155685  This apartment is located in the center of fun...   \n",
       "3  164448  I am renting out a nice double room on the top...   \n",
       "4  170651                                               None   \n",
       "\n",
       "                                         description neighbourhood  \\\n",
       "0  Mitt boende passar par, kompisar och ensamäven...     Södermalm   \n",
       "1  ABOUT THE HOUSE: Modern villa built in 2010. L...     Skarpnäck   \n",
       "2  This apartment is located in the center of fun...     Södermalm   \n",
       "3  I am renting out a nice double room on the top...     Södermalm   \n",
       "4  Welcome to this beautiful, small, and charming...     Södermalm   \n",
       "\n",
       "  neighbourhood_group_cleansed       city zipcode country_code country  \\\n",
       "0                         None  Stockholm  118 53           SE  Sweden   \n",
       "1                         None  Stockholm    None           SE  Sweden   \n",
       "2                         None  Stockholm   11739           SE  Sweden   \n",
       "3                         None  Stockholm   11864           SE  Sweden   \n",
       "4                         None  Stockholm   11737           SE  Sweden   \n",
       "\n",
       "  property_type      price review_scores_rating reviews_per_month  \n",
       "0     Apartment  $1,272.00                   97              2.54  \n",
       "1         House  $1,203.00                 None              None  \n",
       "2     Apartment  $3,209.00                   94              0.22  \n",
       "3     Apartment    $597.00                   97              3.13  \n",
       "4     Apartment    $734.00                   93              0.33  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_listing_clean .limit(10).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['neighbourhood_group_cleansed','zipcode','country_code']\n",
    "df_listing_clean  = df_listing_clean .drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>property_type</th>\n",
       "      <th>price</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145320</td>\n",
       "      <td>Mitt boende passar par, kompisar och ensamäven...</td>\n",
       "      <td>Mitt boende passar par, kompisar och ensamäven...</td>\n",
       "      <td>Södermalm</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$1,272.00</td>\n",
       "      <td>97</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155220</td>\n",
       "      <td>Convenient and spacy home full of positive ene...</td>\n",
       "      <td>ABOUT THE HOUSE: Modern villa built in 2010. L...</td>\n",
       "      <td>Skarpnäck</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>House</td>\n",
       "      <td>$1,203.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155685</td>\n",
       "      <td>This apartment is located in the center of fun...</td>\n",
       "      <td>This apartment is located in the center of fun...</td>\n",
       "      <td>Södermalm</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$3,209.00</td>\n",
       "      <td>94</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164448</td>\n",
       "      <td>I am renting out a nice double room on the top...</td>\n",
       "      <td>I am renting out a nice double room on the top...</td>\n",
       "      <td>Södermalm</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$597.00</td>\n",
       "      <td>97</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170651</td>\n",
       "      <td>None</td>\n",
       "      <td>Welcome to this beautiful, small, and charming...</td>\n",
       "      <td>Södermalm</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$734.00</td>\n",
       "      <td>93</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>206221</td>\n",
       "      <td>None</td>\n",
       "      <td>The region is situated at one of Stockholms mo...</td>\n",
       "      <td>Södermalm</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Bed and breakfast</td>\n",
       "      <td>$665.00</td>\n",
       "      <td>98</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>220233</td>\n",
       "      <td>My apartment is located in Vasastan, a beautif...</td>\n",
       "      <td>My apartment is located in Vasastan, a beautif...</td>\n",
       "      <td>Norrmalm</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$890.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>220851</td>\n",
       "      <td>Welcome!</td>\n",
       "      <td>Welcome! Welcome! One big bedroom ,quiet and c...</td>\n",
       "      <td>Kungsholmen</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$597.00</td>\n",
       "      <td>93</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>242188</td>\n",
       "      <td>I am renting out a nice single room on the top...</td>\n",
       "      <td>I am renting out a nice single room on the top...</td>\n",
       "      <td>Södermalm</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$558.00</td>\n",
       "      <td>97</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>259025</td>\n",
       "      <td>None</td>\n",
       "      <td>If I describe how we live.   You are welcome t...</td>\n",
       "      <td>Rinkeby-Kista</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>$196.00</td>\n",
       "      <td>89</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                            summary  \\\n",
       "0  145320  Mitt boende passar par, kompisar och ensamäven...   \n",
       "1  155220  Convenient and spacy home full of positive ene...   \n",
       "2  155685  This apartment is located in the center of fun...   \n",
       "3  164448  I am renting out a nice double room on the top...   \n",
       "4  170651                                               None   \n",
       "5  206221                                               None   \n",
       "6  220233  My apartment is located in Vasastan, a beautif...   \n",
       "7  220851                                           Welcome!   \n",
       "8  242188  I am renting out a nice single room on the top...   \n",
       "9  259025                                               None   \n",
       "\n",
       "                                         description  neighbourhood  \\\n",
       "0  Mitt boende passar par, kompisar och ensamäven...      Södermalm   \n",
       "1  ABOUT THE HOUSE: Modern villa built in 2010. L...      Skarpnäck   \n",
       "2  This apartment is located in the center of fun...      Södermalm   \n",
       "3  I am renting out a nice double room on the top...      Södermalm   \n",
       "4  Welcome to this beautiful, small, and charming...      Södermalm   \n",
       "5  The region is situated at one of Stockholms mo...      Södermalm   \n",
       "6  My apartment is located in Vasastan, a beautif...       Norrmalm   \n",
       "7  Welcome! Welcome! One big bedroom ,quiet and c...    Kungsholmen   \n",
       "8  I am renting out a nice single room on the top...      Södermalm   \n",
       "9  If I describe how we live.   You are welcome t...  Rinkeby-Kista   \n",
       "\n",
       "        city country      property_type      price review_scores_rating  \\\n",
       "0  Stockholm  Sweden          Apartment  $1,272.00                   97   \n",
       "1  Stockholm  Sweden              House  $1,203.00                 None   \n",
       "2  Stockholm  Sweden          Apartment  $3,209.00                   94   \n",
       "3  Stockholm  Sweden          Apartment    $597.00                   97   \n",
       "4  Stockholm  Sweden          Apartment    $734.00                   93   \n",
       "5  Stockholm  Sweden  Bed and breakfast    $665.00                   98   \n",
       "6  Stockholm  Sweden          Apartment    $890.00                 None   \n",
       "7  Stockholm  Sweden          Apartment    $597.00                   93   \n",
       "8  Stockholm  Sweden          Apartment    $558.00                   97   \n",
       "9  Stockholm  Sweden          Townhouse    $196.00                   89   \n",
       "\n",
       "  reviews_per_month  \n",
       "0              2.54  \n",
       "1              None  \n",
       "2              0.22  \n",
       "3              3.13  \n",
       "4              0.33  \n",
       "5              0.82  \n",
       "6              None  \n",
       "7              0.46  \n",
       "8              3.19  \n",
       "9              0.63  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_listing_clean .limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 2-drop the rows containing any null or NaN values\n",
    "\n",
    "to be don, but i will come back to this later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "df_listing_clean  = df_listing_clean .na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "df_listing_clean .limit(10).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "df_listing.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "df = df.na().drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "drop rows in \"ColumnName\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "ColumnName = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "df.na.drop([ColumnName])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "df.filter(df.col(ColumnName).isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1834.csv.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:198)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:285)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:664)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 231.0 failed 1 times, most recent failure: Lost task 0.0 in stage 231.0 (TID 4181, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:257)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:170)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.IOException: Mkdirs failed to create file:/home/jovyan/work/data/df_listing.csv/_temporary/0/_temporary/attempt_20191127154625_0231_m_000000_4181/property_type=%7BTV,Wifi,%22Air conditioning%22,Elevator,Heating,%22Suitable for events%22,Washer,%22First aid kit%22,%22Fire extinguisher%22,Essentials,Shampoo,Hangers,%22Hair dryer%22,Iron,%22Hot water%22,%22Bed linens%22,%22Ethernet connection%22,Microwave,%22Coffee maker%22,Refrigerator,Dishwasher,%22Dishes and silverware%22} (exists=false, cwd=file:/home/jovyan/work)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:455)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CSVFileFormat.scala:177)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:85)\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.newOutputWriter(FileFormatDataWriter.scala:236)\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.write(FileFormatDataWriter.scala:260)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:245)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:242)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:248)\n\t... 10 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:167)\n\t... 33 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:257)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:170)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.io.IOException: Mkdirs failed to create file:/home/jovyan/work/data/df_listing.csv/_temporary/0/_temporary/attempt_20191127154625_0231_m_000000_4181/property_type=%7BTV,Wifi,%22Air conditioning%22,Elevator,Heating,%22Suitable for events%22,Washer,%22First aid kit%22,%22Fire extinguisher%22,Essentials,Shampoo,Hangers,%22Hair dryer%22,Iron,%22Hot water%22,%22Bed linens%22,%22Ethernet connection%22,Microwave,%22Coffee maker%22,Refrigerator,Dishwasher,%22Dishes and silverware%22} (exists=false, cwd=file:/home/jovyan/work)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:455)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CSVFileFormat.scala:177)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:85)\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.newOutputWriter(FileFormatDataWriter.scala:236)\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.write(FileFormatDataWriter.scala:260)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:245)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:242)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:248)\n\t... 10 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-3c87c100a965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_listing_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'property_type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'df_listing.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue)\u001b[0m\n\u001b[1;32m    929\u001b[0m                        \u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                        encoding=encoding, emptyValue=emptyValue)\n\u001b[0;32m--> 931\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1834.csv.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:198)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:285)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:664)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 231.0 failed 1 times, most recent failure: Lost task 0.0 in stage 231.0 (TID 4181, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:257)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:170)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.IOException: Mkdirs failed to create file:/home/jovyan/work/data/df_listing.csv/_temporary/0/_temporary/attempt_20191127154625_0231_m_000000_4181/property_type=%7BTV,Wifi,%22Air conditioning%22,Elevator,Heating,%22Suitable for events%22,Washer,%22First aid kit%22,%22Fire extinguisher%22,Essentials,Shampoo,Hangers,%22Hair dryer%22,Iron,%22Hot water%22,%22Bed linens%22,%22Ethernet connection%22,Microwave,%22Coffee maker%22,Refrigerator,Dishwasher,%22Dishes and silverware%22} (exists=false, cwd=file:/home/jovyan/work)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:455)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CSVFileFormat.scala:177)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:85)\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.newOutputWriter(FileFormatDataWriter.scala:236)\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.write(FileFormatDataWriter.scala:260)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:245)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:242)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:248)\n\t... 10 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:167)\n\t... 33 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:257)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:170)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.io.IOException: Mkdirs failed to create file:/home/jovyan/work/data/df_listing.csv/_temporary/0/_temporary/attempt_20191127154625_0231_m_000000_4181/property_type=%7BTV,Wifi,%22Air conditioning%22,Elevator,Heating,%22Suitable for events%22,Washer,%22First aid kit%22,%22Fire extinguisher%22,Essentials,Shampoo,Hangers,%22Hair dryer%22,Iron,%22Hot water%22,%22Bed linens%22,%22Ethernet connection%22,Microwave,%22Coffee maker%22,Refrigerator,Dishwasher,%22Dishes and silverware%22} (exists=false, cwd=file:/home/jovyan/work)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:455)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:789)\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)\n\tat org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)\n\tat org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CSVFileFormat.scala:177)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:85)\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.newOutputWriter(FileFormatDataWriter.scala:236)\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.write(FileFormatDataWriter.scala:260)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:245)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:242)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:248)\n\t... 10 more\n"
     ]
    }
   ],
   "source": [
    "df_listing_clean.write.partitionBy('property_type').csv(root+'df_listing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "mycity_review_clean.write.partitionBy('property_type').csv(root+'df_mycity_review.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Part 2: Analysis\n",
    "Use Spark and your favorite tool for data visualization to solve the following tasks.\n",
    "\n",
    "## The basics\n",
    "Compute and show a dataframe with the number of listings and neighbourhoods per city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = df_listing_clean.groupBy('city')\\\n",
    "        .agg(f.countDistinct('neighbourhood'),f.count('id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = df_listing_clean.groupBy('city')\\\n",
    "        .agg(f.countDistinct('neighbourhood').alias('Num_Neighbourhoods'),f.count('id').alias('Num_listings')).sort(f.desc('Num_listings'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+------------+\n",
      "|            city|Num_Neighbourhoods|Num_listings|\n",
      "+----------------+------------------+------------+\n",
      "|           Paris|                63|       61923|\n",
      "|  Greater London|               149|       46521|\n",
      "|          London|               148|       33100|\n",
      "|         Beijing|                61|       32338|\n",
      "|     Los Angeles|                97|       27763|\n",
      "|            Roma|                42|       25374|\n",
      "|          Berlin|                93|       24271|\n",
      "|       Cape Town|                 0|       21895|\n",
      "|         Toronto|               140|       21760|\n",
      "|        New York|                98|       21457|\n",
      "|       København|                21|       20800|\n",
      "|          Madrid|                66|       20642|\n",
      "|       Amsterdam|                44|       19954|\n",
      "|       Barcelona|                68|       19872|\n",
      "|  Rio de Janeiro|                93|       19321|\n",
      "|        Brooklyn|                53|       18776|\n",
      "|          Milano|                24|       17837|\n",
      "|Ciudad de México|                55|       17814|\n",
      "|        Montréal|                44|       16870|\n",
      "|          Lisboa|                49|       15195|\n",
      "+----------------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Based on the table above, you should choose a city that you want to continue your analysis for. The city should have mulitple neighbourhoods with listings in them.\n",
    "\n",
    "Compute and visualize the number of listings of different property types per neighbourhood in your city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "mycity = \"Milan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# mycity_df <-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>property_type</th>\n",
       "      <th>price</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6400</td>\n",
       "      <td>Enjoy your stay at The Studio, a light-filled ...</td>\n",
       "      <td>Enjoy your stay at The Studio, a light-filled ...</td>\n",
       "      <td>Zona 5</td>\n",
       "      <td>Milan</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$100.00</td>\n",
       "      <td>98</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23986</td>\n",
       "      <td>I look forward to welcoming you in my flat; it...</td>\n",
       "      <td>I look forward to welcoming you in my flat; it...</td>\n",
       "      <td>Navigli</td>\n",
       "      <td>Milan</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$150.00</td>\n",
       "      <td>92</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28300</td>\n",
       "      <td>Bella camera in appartamento col terrazzo all'...</td>\n",
       "      <td>I rent one room in Milan for short stays . Bre...</td>\n",
       "      <td>Centro Storico</td>\n",
       "      <td>Milan</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Condominium</td>\n",
       "      <td>$200.00</td>\n",
       "      <td>94</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32119</td>\n",
       "      <td>None</td>\n",
       "      <td>Do you visit Milan for short periods (training...</td>\n",
       "      <td>Zona 2</td>\n",
       "      <td>Milan</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$75.00</td>\n",
       "      <td>97</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32649</td>\n",
       "      <td>Larger group can book Red and Pink (rooms/4653...</td>\n",
       "      <td>Larger group can book Red and Pink (rooms/ (Ph...</td>\n",
       "      <td>Zona 2</td>\n",
       "      <td>Milan</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$70.00</td>\n",
       "      <td>96</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37256</td>\n",
       "      <td>COZY, FULLY FURNISHED, PRIVATE STUDIO IN THE C...</td>\n",
       "      <td>COZY, FULLY FURNISHED, PRIVATE STUDIO IN THE C...</td>\n",
       "      <td>Centro Storico</td>\n",
       "      <td>Milan</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$55.00</td>\n",
       "      <td>98</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40470</td>\n",
       "      <td>None</td>\n",
       "      <td>If you want to visit Milan for a few days our ...</td>\n",
       "      <td>Zona 2</td>\n",
       "      <td>Milan</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$75.00</td>\n",
       "      <td>92</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42732</td>\n",
       "      <td>In the most characteristic and serviced area o...</td>\n",
       "      <td>In the most characteristic and serviced area o...</td>\n",
       "      <td>Centro Storico</td>\n",
       "      <td>Milan</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$290.00</td>\n",
       "      <td>81</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>46536</td>\n",
       "      <td>1) Russian people will have 10% off on site (s...</td>\n",
       "      <td>1) Russian people will have 10% off on site (s...</td>\n",
       "      <td>Zona 2</td>\n",
       "      <td>Milan</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$75.00</td>\n",
       "      <td>90</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52181</td>\n",
       "      <td>None</td>\n",
       "      <td>Modern and elegant two-room apartment, 55 mq, ...</td>\n",
       "      <td>Baggio</td>\n",
       "      <td>Milan</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>$60.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            summary  \\\n",
       "0   6400  Enjoy your stay at The Studio, a light-filled ...   \n",
       "1  23986  I look forward to welcoming you in my flat; it...   \n",
       "2  28300  Bella camera in appartamento col terrazzo all'...   \n",
       "3  32119                                               None   \n",
       "4  32649  Larger group can book Red and Pink (rooms/4653...   \n",
       "5  37256  COZY, FULLY FURNISHED, PRIVATE STUDIO IN THE C...   \n",
       "6  40470                                               None   \n",
       "7  42732  In the most characteristic and serviced area o...   \n",
       "8  46536  1) Russian people will have 10% off on site (s...   \n",
       "9  52181                                               None   \n",
       "\n",
       "                                         description   neighbourhood   city  \\\n",
       "0  Enjoy your stay at The Studio, a light-filled ...          Zona 5  Milan   \n",
       "1  I look forward to welcoming you in my flat; it...         Navigli  Milan   \n",
       "2  I rent one room in Milan for short stays . Bre...  Centro Storico  Milan   \n",
       "3  Do you visit Milan for short periods (training...          Zona 2  Milan   \n",
       "4  Larger group can book Red and Pink (rooms/ (Ph...          Zona 2  Milan   \n",
       "5  COZY, FULLY FURNISHED, PRIVATE STUDIO IN THE C...  Centro Storico  Milan   \n",
       "6  If you want to visit Milan for a few days our ...          Zona 2  Milan   \n",
       "7  In the most characteristic and serviced area o...  Centro Storico  Milan   \n",
       "8  1) Russian people will have 10% off on site (s...          Zona 2  Milan   \n",
       "9  Modern and elegant two-room apartment, 55 mq, ...          Baggio  Milan   \n",
       "\n",
       "  country property_type    price review_scores_rating reviews_per_month  \n",
       "0   Italy     Apartment  $100.00                   98              0.10  \n",
       "1   Italy     Apartment  $150.00                   92              0.16  \n",
       "2   Italy   Condominium  $200.00                   94              3.16  \n",
       "3   Italy     Apartment   $75.00                   97              0.13  \n",
       "4   Italy     Apartment   $70.00                   96              0.26  \n",
       "5   Italy     Apartment   $55.00                   98              0.30  \n",
       "6   Italy     Apartment   $75.00                   92              0.35  \n",
       "7   Italy     Apartment  $290.00                   81              0.29  \n",
       "8   Italy     Apartment   $75.00                   90              0.27  \n",
       "9   Italy     Apartment   $60.00                 None              None  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycity_df = df_listing_clean.filter(f.col('city') == mycity)\n",
    "mycity_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2398"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycity_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pt = mycity_df.select('id','neighbourhood', 'property_type')\\\n",
    "        .groupBy('property_type').count()\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apartment</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Townhouse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guest suite</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Camper/RV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boutique hotel</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Loft</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Guesthouse</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hostel</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Villa</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Other</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    property_type  count\n",
       "0       Apartment   1960\n",
       "1       Townhouse      2\n",
       "2     Guest suite      3\n",
       "3       Camper/RV      1\n",
       "4  Boutique hotel     11\n",
       "5            Loft    151\n",
       "6      Guesthouse      3\n",
       "7          Hostel      2\n",
       "8           Villa      8\n",
       "9           Other      2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "mycity_1 = mycity_df.groupBy('neighbourhood','property_type')\\\n",
    "    .agg(f.count('property_type').alias('property_type_per_neighbourhood'))\\\n",
    "    .select('neighbourhood','property_type', 'property_type_per_neighbourhood')\\\n",
    "    .sort(f.desc(\"neighbourhood\"), f.desc(\"property_type\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>property_type</th>\n",
       "      <th>property_type_per_neighbourhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zona 9</td>\n",
       "      <td>Serviced apartment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zona 9</td>\n",
       "      <td>Loft</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zona 9</td>\n",
       "      <td>House</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zona 9</td>\n",
       "      <td>Condominium</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zona 9</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zona 8</td>\n",
       "      <td>Villa</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zona 8</td>\n",
       "      <td>Loft</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zona 8</td>\n",
       "      <td>House</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zona 8</td>\n",
       "      <td>Guesthouse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zona 8</td>\n",
       "      <td>Condominium</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zona 8</td>\n",
       "      <td>Bed and breakfast</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Zona 8</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zona 7</td>\n",
       "      <td>Villa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Zona 7</td>\n",
       "      <td>Loft</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Zona 7</td>\n",
       "      <td>House</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Zona 7</td>\n",
       "      <td>Condominium</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Zona 7</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Zona 6</td>\n",
       "      <td>Tiny house</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Zona 6</td>\n",
       "      <td>Serviced apartment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Zona 6</td>\n",
       "      <td>Loft</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbourhood       property_type  property_type_per_neighbourhood\n",
       "0         Zona 9  Serviced apartment                                1\n",
       "1         Zona 9                Loft                               14\n",
       "2         Zona 9               House                                5\n",
       "3         Zona 9         Condominium                                7\n",
       "4         Zona 9           Apartment                              129\n",
       "5         Zona 8               Villa                                3\n",
       "6         Zona 8                Loft                                8\n",
       "7         Zona 8               House                                5\n",
       "8         Zona 8          Guesthouse                                1\n",
       "9         Zona 8         Condominium                               13\n",
       "10        Zona 8   Bed and breakfast                                1\n",
       "11        Zona 8           Apartment                              156\n",
       "12        Zona 7               Villa                                1\n",
       "13        Zona 7                Loft                                3\n",
       "14        Zona 7               House                                9\n",
       "15        Zona 7         Condominium                               11\n",
       "16        Zona 7           Apartment                              116\n",
       "17        Zona 6          Tiny house                                1\n",
       "18        Zona 6  Serviced apartment                                1\n",
       "19        Zona 6                Loft                               23"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycity_1.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Prices\n",
    "Compute the minimum, maximum and average listing price in your city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def price_to_numeric(x):\n",
    "    return float(x.replace(',', '')[1:])\n",
    "\n",
    "p2numeric_udf = f.udf(price_to_numeric, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#|-- price: string (nullable = true)\n",
    "# update Null\n",
    "#res = res.withColumn(\"col2\", F.when(F.col(\"col2\").isNull(), 0).otherwise(F.col(\"col2\")))\n",
    "mycity_df = mycity_df.withColumn('price',p2numeric_udf(f.col('price')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "mycity_prices = mycity_df.select(f.min('Price'), f.max('Price'), f.avg('Price'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min(Price)</th>\n",
       "      <th>max(Price)</th>\n",
       "      <th>avg(Price)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>110.338616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min(Price)  max(Price)  avg(Price)\n",
       "0         9.0      2400.0  110.338616"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycity_prices.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Compute and visualize the distribution of listing prices in your city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of Price')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = mycity_df.select('price').toPandas().plot(kind='hist', bins=500)\n",
    "ax.set_xlim([0, 3000])\n",
    "ax.set_xlabel('price')\n",
    "ax.set_title('Histogram of Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The value of a listing is its rating divided by its price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "mycity_w_value = mycity_df.withColumn('value', f.round(f.col('review_scores_rating')/f.col('price'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Compute and show a dataframe with the 3 highest valued listings in each neighbourhood.\n",
    "\n",
    "-  with a window function we basically treat each group as a separate dataframe. for each neighbourhood we list in decreasing value the listings and we store them in the window function.\n",
    "-  then we add a new column in the orginal df with the values from the values_widonw(df) \n",
    "- finally we filter the values with ValueRank < 3, taking some columns of the df and sorting in decreasing order of value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------------+-----+-----+\n",
      "|      id|neighbourhood|review_scores_rating|price|value|\n",
      "+--------+-------------+--------------------+-----+-----+\n",
      "| 2657825|       Affori|                  97| 35.0| 2.77|\n",
      "| 2739325|       Affori|                  92|250.0| 0.37|\n",
      "| 2400202|       Affori|                null|100.0| null|\n",
      "| 2783727|       Baggio|                 100| 40.0|  2.5|\n",
      "|  779841|       Baggio|                  82| 89.0| 0.92|\n",
      "|26406985|       Baggio|                 100|198.0| 0.51|\n",
      "| 3083570|       Barona|                  92| 38.0| 2.42|\n",
      "|  667264|       Barona|                  93| 39.0| 2.38|\n",
      "| 4350320|       Barona|                  80| 35.0| 2.29|\n",
      "| 3161334|       Bovisa|                  93| 16.0| 5.81|\n",
      "|  737797|       Bovisa|                  99| 21.0| 4.71|\n",
      "| 9573933|       Bovisa|                  66| 18.0| 3.67|\n",
      "| 1703576|    Bovisasca|                  94| 30.0| 3.13|\n",
      "| 4254200|        Brera|                  96| 62.0| 1.55|\n",
      "| 4337304|        Brera|                  94| 69.0| 1.36|\n",
      "| 2161984|        Brera|                  93| 72.0| 1.29|\n",
      "|23934299|     Bruzzano|                  93| 50.0| 1.86|\n",
      "| 1603944|     Bruzzano|                  98| 60.0| 1.63|\n",
      "|27592033|   Calvairate|                  96| 35.0| 2.74|\n",
      "|35570061|   Calvairate|                 100| 40.0|  2.5|\n",
      "+--------+-------------+--------------------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "values_window = Window.partitionBy('neighbourhood').orderBy(f.desc('value'))\n",
    "\n",
    "ranked_values = mycity_w_value.withColumn('ValueRank', f.rank().over(values_window))\n",
    "ranked_values.filter(f.col('ValueRank') <= 3)\\\n",
    "    .select('id', 'neighbourhood', 'review_scores_rating', 'price', 'value')\\\n",
    "    .orderBy('neighbourhood', f.desc('value'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Trends\n",
    "Now we want to analyze the \"popularity\" of your city. The data does not contain the number of bookings per listing, but we have a large number of reviews, and we will assume that this is a good indicator of activity on listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- listing_id: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- reviewer_id: string (nullable = true)\n",
      " |-- reviewer_name: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145320</td>\n",
       "      <td>156423122</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>123386382</td>\n",
       "      <td>Erwin</td>\n",
       "      <td>Prima plek om Stockholm te bekijken. Alles is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145320</td>\n",
       "      <td>170211906</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>123091743</td>\n",
       "      <td>Anne</td>\n",
       "      <td>Cosy and clean flat in quiet neighbourhood clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145320</td>\n",
       "      <td>172169175</td>\n",
       "      <td>2017-07-20</td>\n",
       "      <td>78004</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>The host canceled this reservation 37 days bef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145320</td>\n",
       "      <td>176647581</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>103178743</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Kim's place was outstanding and comfortable. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145320</td>\n",
       "      <td>185676021</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>4023961</td>\n",
       "      <td>Alexander</td>\n",
       "      <td>great spacious apartment in a nice residential...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>145320</td>\n",
       "      <td>189668224</td>\n",
       "      <td>2017-09-02</td>\n",
       "      <td>142869362</td>\n",
       "      <td>Heiko</td>\n",
       "      <td>Kim is a very friendly person.A lot of advice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>145320</td>\n",
       "      <td>191894030</td>\n",
       "      <td>2017-09-09</td>\n",
       "      <td>25194419</td>\n",
       "      <td>Jason</td>\n",
       "      <td>The apartment is cost and Kim was a terrific h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>145320</td>\n",
       "      <td>193316070</td>\n",
       "      <td>2017-09-13</td>\n",
       "      <td>52056015</td>\n",
       "      <td>David</td>\n",
       "      <td>Nicely appointed, in a great location, with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>145320</td>\n",
       "      <td>196760607</td>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>3980456</td>\n",
       "      <td>Janne</td>\n",
       "      <td>It was a pleasure staying at Kim’s apartment i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>145320</td>\n",
       "      <td>201885633</td>\n",
       "      <td>2017-10-09</td>\n",
       "      <td>72139946</td>\n",
       "      <td>Florence</td>\n",
       "      <td>Kim's place is simply amazing, it was such a c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  listing_id         id        date reviewer_id reviewer_name  \\\n",
       "0     145320  156423122  2017-05-30   123386382         Erwin   \n",
       "1     145320  170211906  2017-07-15   123091743          Anne   \n",
       "2     145320  172169175  2017-07-20       78004      Patricia   \n",
       "3     145320  176647581  2017-07-31   103178743     Charlotte   \n",
       "4     145320  185676021  2017-08-22     4023961     Alexander   \n",
       "5     145320  189668224  2017-09-02   142869362         Heiko   \n",
       "6     145320  191894030  2017-09-09    25194419         Jason   \n",
       "7     145320  193316070  2017-09-13    52056015         David   \n",
       "8     145320  196760607  2017-09-24     3980456         Janne   \n",
       "9     145320  201885633  2017-10-09    72139946      Florence   \n",
       "\n",
       "                                            comments  \n",
       "0  Prima plek om Stockholm te bekijken. Alles is ...  \n",
       "1  Cosy and clean flat in quiet neighbourhood clo...  \n",
       "2  The host canceled this reservation 37 days bef...  \n",
       "3  Kim's place was outstanding and comfortable. W...  \n",
       "4  great spacious apartment in a nice residential...  \n",
       "5  Kim is a very friendly person.A lot of advice ...  \n",
       "6  The apartment is cost and Kim was a terrific h...  \n",
       "7  Nicely appointed, in a great location, with a ...  \n",
       "8  It was a pleasure staying at Kim’s apartment i...  \n",
       "9  Kim's place is simply amazing, it was such a c...  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp(df_reviews, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We want to join the listing_df and the review_df on the listing_id and id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "mycity_review = mycity_df.select('neighbourhood', 'property_type', f.col('id').alias('id_'))\\\n",
    "    .join(df_reviews, (df_reviews.listing_id == f.col('id_')), 'inner')\\\n",
    "    .drop('id_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>property_type</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1680685</td>\n",
       "      <td>13048057</td>\n",
       "      <td>2014-05-18</td>\n",
       "      <td>14851795</td>\n",
       "      <td>Francesca</td>\n",
       "      <td>La mia esperienza da Costanza è stata ottima.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1680685</td>\n",
       "      <td>13321021</td>\n",
       "      <td>2014-05-25</td>\n",
       "      <td>8280853</td>\n",
       "      <td>Kseniya</td>\n",
       "      <td>Costanza is a good and responsive host!\\r\\nApa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1680685</td>\n",
       "      <td>14500188</td>\n",
       "      <td>2014-06-21</td>\n",
       "      <td>13034533</td>\n",
       "      <td>Fede</td>\n",
       "      <td>The reservation was canceled 9 days before arr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1680685</td>\n",
       "      <td>18832023</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>19965087</td>\n",
       "      <td>Claudia</td>\n",
       "      <td>Una casa calda e accogliente è raro trovarla m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1680685</td>\n",
       "      <td>23779550</td>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>18961641</td>\n",
       "      <td>Caterina</td>\n",
       "      <td>Costanza ha sido muy amable y nos ha ayudado c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1680685</td>\n",
       "      <td>24243690</td>\n",
       "      <td>2014-12-23</td>\n",
       "      <td>23884894</td>\n",
       "      <td>Carlo</td>\n",
       "      <td>Costanza è stata una host gentile e disponibil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1680685</td>\n",
       "      <td>24958163</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>24405727</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>Costanza is a very nice host. She arranged for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1680685</td>\n",
       "      <td>28566032</td>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>28014638</td>\n",
       "      <td>Angelo</td>\n",
       "      <td>Si tratta di un appartamento comodo, carino, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1680685</td>\n",
       "      <td>30196054</td>\n",
       "      <td>2015-04-19</td>\n",
       "      <td>22814177</td>\n",
       "      <td>Valeria</td>\n",
       "      <td>Consiglio a tutti l`appartamento di Costanza:s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1680685</td>\n",
       "      <td>33572717</td>\n",
       "      <td>2015-05-30</td>\n",
       "      <td>11682903</td>\n",
       "      <td>Dong Qyu (David)</td>\n",
       "      <td>I stayed at Costanza's place for 6 weeks, and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  neighbourhood property_type listing_id        id        date reviewer_id  \\\n",
       "0   Città Studi     Apartment    1680685  13048057  2014-05-18    14851795   \n",
       "1   Città Studi     Apartment    1680685  13321021  2014-05-25     8280853   \n",
       "2   Città Studi     Apartment    1680685  14500188  2014-06-21    13034533   \n",
       "3   Città Studi     Apartment    1680685  18832023  2014-09-01    19965087   \n",
       "4   Città Studi     Apartment    1680685  23779550  2014-12-09    18961641   \n",
       "5   Città Studi     Apartment    1680685  24243690  2014-12-23    23884894   \n",
       "6   Città Studi     Apartment    1680685  24958163  2015-01-04    24405727   \n",
       "7   Città Studi     Apartment    1680685  28566032  2015-03-26    28014638   \n",
       "8   Città Studi     Apartment    1680685  30196054  2015-04-19    22814177   \n",
       "9   Città Studi     Apartment    1680685  33572717  2015-05-30    11682903   \n",
       "\n",
       "      reviewer_name                                           comments  \n",
       "0         Francesca  La mia esperienza da Costanza è stata ottima.\\...  \n",
       "1           Kseniya  Costanza is a good and responsive host!\\r\\nApa...  \n",
       "2              Fede  The reservation was canceled 9 days before arr...  \n",
       "3           Claudia  Una casa calda e accogliente è raro trovarla m...  \n",
       "4          Caterina  Costanza ha sido muy amable y nos ha ayudado c...  \n",
       "5             Carlo  Costanza è stata una host gentile e disponibil...  \n",
       "6          Danielle  Costanza is a very nice host. She arranged for...  \n",
       "7            Angelo  Si tratta di un appartamento comodo, carino, m...  \n",
       "8           Valeria  Consiglio a tutti l`appartamento di Costanza:s...  \n",
       "9  Dong Qyu (David)  I stayed at Costanza's place for 6 weeks, and ...  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycity_review.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## why we carried on the property types? also we can get rid of many columns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['property_type','reviewer_id','reviewer_id']\n",
    "mycity_review_clean  = mycity_review.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# mycity_review_clean <-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>1680685</td>\n",
       "      <td>13048057</td>\n",
       "      <td>2014-05-18</td>\n",
       "      <td>Francesca</td>\n",
       "      <td>La mia esperienza da Costanza è stata ottima.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>1680685</td>\n",
       "      <td>13321021</td>\n",
       "      <td>2014-05-25</td>\n",
       "      <td>Kseniya</td>\n",
       "      <td>Costanza is a good and responsive host!\\r\\nApa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>1680685</td>\n",
       "      <td>14500188</td>\n",
       "      <td>2014-06-21</td>\n",
       "      <td>Fede</td>\n",
       "      <td>The reservation was canceled 9 days before arr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>1680685</td>\n",
       "      <td>18832023</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>Claudia</td>\n",
       "      <td>Una casa calda e accogliente è raro trovarla m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>1680685</td>\n",
       "      <td>23779550</td>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>Caterina</td>\n",
       "      <td>Costanza ha sido muy amable y nos ha ayudado c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>1680685</td>\n",
       "      <td>24243690</td>\n",
       "      <td>2014-12-23</td>\n",
       "      <td>Carlo</td>\n",
       "      <td>Costanza è stata una host gentile e disponibil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>1680685</td>\n",
       "      <td>24958163</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>Costanza is a very nice host. She arranged for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>1680685</td>\n",
       "      <td>28566032</td>\n",
       "      <td>2015-03-26</td>\n",
       "      <td>Angelo</td>\n",
       "      <td>Si tratta di un appartamento comodo, carino, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>1680685</td>\n",
       "      <td>30196054</td>\n",
       "      <td>2015-04-19</td>\n",
       "      <td>Valeria</td>\n",
       "      <td>Consiglio a tutti l`appartamento di Costanza:s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Città Studi</td>\n",
       "      <td>1680685</td>\n",
       "      <td>33572717</td>\n",
       "      <td>2015-05-30</td>\n",
       "      <td>Dong Qyu (David)</td>\n",
       "      <td>I stayed at Costanza's place for 6 weeks, and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  neighbourhood listing_id        id        date     reviewer_name  \\\n",
       "0   Città Studi    1680685  13048057  2014-05-18         Francesca   \n",
       "1   Città Studi    1680685  13321021  2014-05-25           Kseniya   \n",
       "2   Città Studi    1680685  14500188  2014-06-21              Fede   \n",
       "3   Città Studi    1680685  18832023  2014-09-01           Claudia   \n",
       "4   Città Studi    1680685  23779550  2014-12-09          Caterina   \n",
       "5   Città Studi    1680685  24243690  2014-12-23             Carlo   \n",
       "6   Città Studi    1680685  24958163  2015-01-04          Danielle   \n",
       "7   Città Studi    1680685  28566032  2015-03-26            Angelo   \n",
       "8   Città Studi    1680685  30196054  2015-04-19           Valeria   \n",
       "9   Città Studi    1680685  33572717  2015-05-30  Dong Qyu (David)   \n",
       "\n",
       "                                            comments  \n",
       "0  La mia esperienza da Costanza è stata ottima.\\...  \n",
       "1  Costanza is a good and responsive host!\\r\\nApa...  \n",
       "2  The reservation was canceled 9 days before arr...  \n",
       "3  Una casa calda e accogliente è raro trovarla m...  \n",
       "4  Costanza ha sido muy amable y nos ha ayudado c...  \n",
       "5  Costanza è stata una host gentile e disponibil...  \n",
       "6  Costanza is a very nice host. She arranged for...  \n",
       "7  Si tratta di un appartamento comodo, carino, m...  \n",
       "8  Consiglio a tutti l`appartamento di Costanza:s...  \n",
       "9  I stayed at Costanza's place for 6 weeks, and ...  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycity_review_clean.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### - Compute and visualize the popularity (i.e., number of reviews) of your city over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "mycity_1 = mycity_df.groupBy('neighbourhood','property_type')\\\n",
    "    .agg(f.count('property_type').alias('property_type_per_neighbourhood'))\\\n",
    "    .select('neighbourhood','property_type', 'property_type_per_neighbourhood')\\\n",
    "    .sort(f.desc(\"neighbourhood\"), f.desc(\"property_type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GroupedData' object has no attribute 'sort'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-e8f7712a48a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmycity_pop_by_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmycity_review\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GroupedData' object has no attribute 'sort'"
     ]
    }
   ],
   "source": [
    "mycity_pop_by_year = mycity_review.groupby(f.year('date').alias('year'))\\\n",
    "                        .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-e3afd0b03436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmycity_pop_by_year\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-a860abed4d2a>\u001b[0m in \u001b[0;36mdisp\u001b[0;34m(x, n)\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrows\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \"\"\"\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2143\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "disp(mycity_pop_by_year, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## how to sort a GroupedData object?\n",
    "\n",
    "mycity_pop_by_year\n",
    "AttributeError: 'GroupedData' object has no attribute 'sort'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-56abbc8b1289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmycity_pop_by_year\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'years'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Histogram of City Popularity per year'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "ax = mycity_review('count').plot(kind='hist', bins=500)\n",
    "ax.set_xlim([0, 3000])\n",
    "ax.set_xlabel('years')\n",
    "ax.set_title('Histogram of City Popularity per year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## how to plot count(y) vs year(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### - Compute and visualize the popularity of neighbourhoods over time. \n",
    "\n",
    "If there are many neighbourhoods in your city, you should select a few interesting ones for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "values_window = Window.partitionBy('neighbourhood').orderBy(f.desc('value'))\n",
    "ranked_values = mycity_w_value.withColumn('ValueRank', f.rank().over(values_window))\n",
    "ranked_values.filter(f.col('ValueRank') <= 3)\\\n",
    "    .select('id', 'neighbourhood', 'review_scores_rating', 'price', 'value')\\\n",
    "    .orderBy('neighbourhood', f.desc('value'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "myneigh_pop_by_year  = mycity_review.groupby('neighbourhood',f.year('date'))\\\n",
    "                    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+-----+\n",
      "|     neighbourhood|year(date)|count|\n",
      "+------------------+----------+-----+\n",
      "|            Zona 2|      2012|  108|\n",
      "|    Centro Storico|      2014| 2104|\n",
      "|            Zona 7|      2015|  819|\n",
      "|            Zona 2|      2016| 1807|\n",
      "|            Affori|      2016|   18|\n",
      "|            Zona 6|      2012|  103|\n",
      "|            Zona 9|      2014|  695|\n",
      "|             Brera|      2019|  157|\n",
      "|            Zona 8|      2015| 1345|\n",
      "|            Zona 7|      2011|   27|\n",
      "|             Brera|      2016|  262|\n",
      "|       Città Studi|      2016|  404|\n",
      "|            Zona 9|      2016| 1099|\n",
      "|      Porta Romana|      2015|  330|\n",
      "|Centro Direzionale|      2014|  408|\n",
      "|            Zona 2|      2019| 1329|\n",
      "|            Zona 2|      2014| 1040|\n",
      "|            Zona 8|      2018|  911|\n",
      "|         Chinatown|      2019|   89|\n",
      "|            Zona 4|      2014|  401|\n",
      "+------------------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myneigh_pop_by_year.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### - Compute and visualize the popularity of your city by season. \n",
    "For example, visualize the popularity of your city per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "mycity_pop_by_season = mycity_review.groupby(f.year('date'),f.month('date')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+\n",
      "|year(date)|month(date)|count|\n",
      "+----------+-----------+-----+\n",
      "|      2012|         10|  181|\n",
      "|      2010|         12|    1|\n",
      "|      2010|          7|    1|\n",
      "|      2015|          2|  911|\n",
      "|      2017|          3| 1116|\n",
      "|      2017|          8| 1056|\n",
      "|      2014|          4| 1092|\n",
      "|      2019|          5| 1571|\n",
      "|      2018|         10| 1610|\n",
      "|      2017|         10| 1738|\n",
      "|      2016|          7| 1482|\n",
      "|      2015|         12|  816|\n",
      "|      2016|         11| 1217|\n",
      "|      2019|          3| 1231|\n",
      "|      2013|          2|  127|\n",
      "|      2012|          8|   55|\n",
      "|      2012|         12|  107|\n",
      "|      2012|          4|  148|\n",
      "|      2018|          1| 1143|\n",
      "|      2018|          3| 1334|\n",
      "+----------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mycity_pop_by_season.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Reviews\n",
    "In this part you should determine which words used in reviews that are the most positive. \n",
    "\n",
    "The individual reviews do not have a rating of the listing, so we will assume that each review gave the average rating to the listing, i.e., the one on the listing.\n",
    "\n",
    "You should assign a positivity weight to each word seen in reviews and list the words with the highest weight. It is up to you to decide what the weight should be. For example, it can be a function of the rating on the listing on which it occurs, the number of reviews it occurs in, and the number of unique listings for which it was used to review.\n",
    "\n",
    "Depending on your choice of weight function, you may also want to do some filtering of words. For example, remove words that only occur in a few reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "###### ideas\n",
    "- \"The individual reviews do not have a rating of the listing\" ---> there fore we use review_scores_rating is actually a rating of eachthe listing for each individual review \n",
    "\n",
    "- my impression is that they dont ask to apply a pre trained NLP model (we pour all the words all together and they come out of the model in vectors with meaning), but that we follow their indications.\n",
    "\n",
    "\n",
    "- df1 = mycity_review_clean\n",
    "- df2 = mycity_df\n",
    "- join df1 and df2 on \"id\" column. careful with df1, has many id-ish columns.\n",
    "\n",
    "- natural language processing task, tool? \n",
    "    - Natural Language Toolkit(NLTK)?\n",
    "\n",
    "- we want to sort of count or estimate frequencies of words\n",
    "- we want to focus on the most frequent and rapresentative words of the reviews\n",
    "- we want a score of positivity or negativity for each word and the overall review score is given by the sum of the scores of the words\n",
    "- rare words should have an higher score (one doesnt use flabbergasting as much as good)\n",
    "- more frequent words should have an higher score? nah maybe not\n",
    "- we can assume longer review have more significative words\n",
    "\n",
    "\n",
    "###### what? \n",
    "1- LIST_OF_RAPRESENTATIVE_WORDS (n =40); COUNT_TOT_IN_NEG_REVIEWS; COUNT_TOT_IN_POS_REVIEWS; COUNT_TOT ; \n",
    "    - 1)\"Good\"; 10, 80, 90\n",
    "    - ....\n",
    "    - 40)\"Disgusting\"; 30, 10, 40\n",
    " \n",
    "\n",
    "2-RARE if COUNT_TOT< 0.5*COUNT_AVERAGE\n",
    "    - \"Good\" not RARE    r = 1\n",
    "    - \"Disgusting\" RARE  r = 1.5\n",
    "\n",
    "3 - get the weights for each rapresentative word: \n",
    "    - eg .WEIGHT = P * review_scores_rating/100 *r\n",
    "    - P = (1,-1) # Positive or negative\n",
    "    - review_scores_rating = [0,1] # 85,32 etc \n",
    "    - r = 1 or 1.5 # rarity factor\n",
    "    \n",
    "    \n",
    "4 - example\n",
    "    - word ; WEIGHT \n",
    "    - 1)\"Good\"; 0.75\n",
    "    - 2)\"OK\"; 0.6\n",
    "    - 3)\"flabbergasting\";0.95\n",
    "    - ....\n",
    "    - 40)\"Disgusting\"; -0.80\n",
    "\n",
    "\n",
    "\n",
    "###### how? \n",
    "\n",
    "1-LIST_OF_RAPRESENTATIVE_WORDS (n =40)\n",
    "- we take all the reviews and trasform them in bag of words, tokenization\n",
    "- we output the 10-20 most frequent words overall\n",
    "    we expect them to be non useful fillers ('the', 'end', 'but', 'a', 'an', 'not' etc)\n",
    "    NOTE: stripping not can create problems... but expressions like \"not good\" will be most likely missinterpreted\n",
    "\n",
    "- we threshold reviews \n",
    "    - review_scores_rating > 60 review_score =(1) POSITIVE\n",
    "    - review_scores_rating < 60 review_score =(0) NEGATIVE\n",
    "\n",
    "- we take only the positive reviews and trasform them in bag of words, tokenization\n",
    "- we output the 40-60 most frequent words overall, so we keep their counting, those we expect to be the fillers and the most rapresentative words (great, beautiful etc) \n",
    "    - we make the difference and we get LIST_OF_RAPRESENTATIVE_WORDS_POSITIVE\n",
    "- we repeat the same for the negative reviews, we get the LIST_OF_RAPRESENTATIVE_WORDS_NEGATIVE\n",
    "- then its done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## join the two df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "A_reviews = mycity_review_clean\n",
    "A_listings = mycity_df\n",
    "\n",
    "reviews_scores = A_listings.select('review_scores_rating', 'id').join(A_reviews, A_listings.id == A_reviews.listing_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_scores_rating: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- listing_id: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- reviewer_name: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#disp(reviews_scores, n=10)\n",
    "reviews_scores.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"comments\", outputCol=\"words\") \n",
    "tokenized = tokenizer.transform(reviews_scores)\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "filtered = remover.transform(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_scores_rating: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- listing_id: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- reviewer_name: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      " |-- bag_of_words: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_scores.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_scores_rating: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- listing_id: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- reviewer_name: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      " |-- bag_of_words: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_scores_rating: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- listing_id: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- reviewer_name: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      " |-- bag_of_words: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered_words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "filtered.show().take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "filtered.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_words_from_review(reviews):\n",
    "    tokenizer = Tokenizer(inputCol=\"comments\", outputCol=\"bag_of_words\")\n",
    "    tokenized = tokenizer.transform(reviews_scores)\n",
    "    remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\"\n",
    "    return (tokenized,remover) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "reviews_scores = reviews_scores.withColumn(\"bag_of_words\", lit(None).cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "reviews_scores = reviews_scores.withColumn(\"bag_of_words\", get_words_from_review(\"reviews\").cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
